# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply prepend
# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


# Global tags can be specified here in key="value" format.
[global_tags]
  ## Environment variables can be used as tags, and throughout the config file


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "3s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
  ## output, and will flush this buffer on a successful write. Oldest metrics
  ## are dropped first when this buffer fills.
  ## This buffer only fills when writes fail to output plugin(s).
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. You shouldn't set this below
  ## interval. Maximum flush_interval will be flush_interval + flush_jitter
  flush_interval = "3s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Logging configuration:
  ## Run telegraf with debug log messages.
  debug = false
  ## Run telegraf in quiet mode (error log messages only).
  quiet = false
  ## Specify the log file name. The empty string means to log to stderr.
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

[[outputs.file]]
    ## Files to write to, "stdout" is a specially handled file.
  files = ["stdout", "/tmp/telegraf.log"]

  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  data_format = "influx"


###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################

# # Apply metric modifications using override semantics.
# [[processors.override]]
#   ## All modifications on inputs and aggregators can be overridden:
#   # name_override = "new_name"
#   # name_prefix = "new_name_prefix"
#   # name_suffix = "new_name_suffix"
#
#   ## Tags to be added (all values must be strings)
#   # [processors.override.tags]
#   #   additional_tag = "tag_value"


# # Print all metrics that pass through this filter.
# [[processors.printer]]



###############################################################################
#                            AGGREGATOR PLUGINS                               #
###############################################################################

# # Keep the aggregate basicstats of each metric passing through.
# [[aggregators.basicstats]]
#   ## General Aggregator Arguments:
#   ## The period on which to flush & clear the aggregator.
#   period = "30s"
#   ## If true, the original metric will be dropped by the
#   ## aggregator and will not get sent to the output plugins.
#   drop_original = false


# # Create aggregate histograms.
# [[aggregators.histogram]]
#   ## The period in which to flush the aggregator.
#   period = "30s"
#
#   ## If true, the original metric will be dropped by the
#   ## aggregator and will not get sent to the output plugins.
#   drop_original = false
#
#   ## Example config that aggregates all fields of the metric.
#   # [[aggregators.histogram.config]]
#   #   ## The set of buckets.
#   #   buckets = [0.0, 15.6, 34.5, 49.1, 71.5, 80.5, 94.5, 100.0]
#   #   ## The name of metric.
#   #   measurement_name = "cpu"
#
#   ## Example config that aggregates only specific fields of the metric.
#   # [[aggregators.histogram.config]]
#   #   ## The set of buckets.
#   #   buckets = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]
#   #   ## The name of metric.
#   #   measurement_name = "diskio"
#   #   ## The concrete fields of metric
#   #   fields = ["io_time", "read_time", "write_time"]


# # Keep the aggregate min/max of each metric passing through.
# [[aggregators.minmax]]
#   ## General Aggregator Arguments:
#   ## The period on which to flush & clear the aggregator.
#   period = "30s"
#   ## If true, the original metric will be dropped by the
#   ## aggregator and will not get sent to the output plugins.
#   drop_original = false



###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


###############################################################################
#                            SERVICE INPUT PLUGINS                            #
###############################################################################

# # Statsd UDP/TCP Server
# [[inputs.statsd]]
#   ## Protocol, must be "tcp", "udp", "udp4" or "udp6" (default=udp)
#   protocol = "udp"

#   ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)
#   max_tcp_connections = 250

#   ## Enable TCP keep alive probes (default=false)
#   tcp_keep_alive = false

#   ## Specifies the keep-alive period for an active network connection.
#   ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.
#   ## Defaults to the OS configuration.
#   # tcp_keep_alive_period = "2h"

#   ## Address and port to host UDP listener on
#   service_address = ":8125"

#   ## The following configuration options control when telegraf clears it's cache
#   ## of previous values. If set to false, then telegraf will only clear it's
#   ## cache when the daemon is restarted.
#   ## Reset gauges every interval (default=true)
#   delete_gauges = true
#   ## Reset counters every interval (default=true)
#   delete_counters = true
#   ## Reset sets every interval (default=true)
#   delete_sets = true
#   ## Reset timings & histograms every interval (default=true)
#   delete_timings = true

#   ## Percentiles to calculate for timing & histogram stats
#   percentiles = [90]

#   ## separator to use between elements of a statsd metric
#   metric_separator = "_"

#   ## Parses tags in the datadog statsd format
#   ## http://docs.datadoghq.com/guides/dogstatsd/
#   parse_data_dog_tags = false

#   ## Statsd data translation templates, more info can be read here:
#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite
#   # templates = [
#   #     "cpu.* measurement*"
#   # ]

#   ## Number of UDP messages allowed to queue up, once filled,
#   ## the statsd server will start dropping packets
#   allowed_pending_messages = 10000

#   ## Number of timing/histogram values to track per-measurement in the
#   ## calculation of percentiles. Raising this limit increases the accuracy
#   ## of percentiles but also increases the memory usage and cpu time.
#   percentile_limit = 1000

# CPU metrics
# https://github.com/influxdata/telegraf/blob/master/plugins/inputs/system/CPU_README.md
# [[inputs.cpu]]
#   percpu = true
#   totalcpu = true

# Disk metrics
# https://github.com/influxdata/telegraf/blob/master/plugins/inputs/system/DISK_README.md
# [[inputs.disk]]
#   mount_points = ["/"]

# Memory metrics
# https://github.com/influxdata/telegraf/blob/master/plugins/inputs/system/MEM_README.md
# [[inputs.mem]]

# Network metrics
# https://github.com/influxdata/telegraf/blob/master/plugins/inputs/system/NET_README.md
# [[inputs.net]]
#   interfaces = ["ens*", "eth*", "enp0s*"]
#   ignore_protocol_stats = false

# CloudWatch metrics
# https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cloudwatch
[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/ApplicationELB"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/DynamoDB"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/EBS"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/EC2"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/ELB"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/ES"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/EMR"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/Logs"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/NATGateway"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/RDS"
  ratelimit = 30

[[inputs.cloudwatch]]
  region = "ap-southeast-1"
  access_key = "{{ access_key }}"
  secret_key = "{{ secret_key }}"
  period = "5m"
  delay = "5m"
  interval = "5m"
  namespace = "AWS/S3"
  ratelimit = 30
